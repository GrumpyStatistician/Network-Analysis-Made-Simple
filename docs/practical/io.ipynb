{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In order to get you familiar with graph ideas,\n",
    "I have deliberately chosen to steer away from\n",
    "the more pedantic matters\n",
    "of loading graph data to and from disk.\n",
    "That said, the following scenario will eventually happen,\n",
    "where a graph dataset lands on your lap,\n",
    "and you'll need to load it in and run with it.\n",
    "\n",
    "Thus, we're going to go through graph I/O,\n",
    "specifically the APIs on how to convert\n",
    "graph data that comes to you\n",
    "into that magical NetworkX object `G`.\n",
    "\n",
    "Let's get going!\n",
    "\n",
    "## Graph Data as Tables\n",
    "\n",
    "Let's recall what we've learned in the introductory chapters.\n",
    "Graphs can be represented using two **sets**:\n",
    "\n",
    "- Node set\n",
    "- Edge set\n",
    "\n",
    "### Node set as tables\n",
    "\n",
    "Let's say we had a graph with 3 nodes in it: `A, B, C`.\n",
    "We could represent it in plain text, computer-readable format:\n",
    "\n",
    "```\n",
    "A\n",
    "B\n",
    "C\n",
    "```\n",
    "\n",
    "Suppose the nodes also had metadata.\n",
    "Then, we could tag on metadata as well:\n",
    "\n",
    "```\n",
    "A, circle, 5\n",
    "B, circle, 7\n",
    "C, square, 9\n",
    "```\n",
    "\n",
    "Does this look familiar to you?\n",
    "Yes, node sets can be stored in CSV format,\n",
    "with one of the columns being node ID,\n",
    "and the rest of the columns being metadata.\n",
    "\n",
    "### Edge set as tables\n",
    "\n",
    "If, between the nodes, we had 4 edges (this is a directed graph),\n",
    "we can also represent those edges in plain text, computer-readable format:\n",
    "\n",
    "```\n",
    "A, C\n",
    "B, C\n",
    "A, B\n",
    "C, A\n",
    "```\n",
    "\n",
    "And let's say we also had other metadata,\n",
    "we can represent it in the same CSV format:\n",
    "\n",
    "```\n",
    "A, C, red\n",
    "B, C, orange\n",
    "A, B, yellow\n",
    "C, A, green\n",
    "```\n",
    "\n",
    "If you've been in the data world for a while,\n",
    "this should not look foreign to you.\n",
    "Yes, edge sets can be stored in CSV format too!\n",
    "Two of the columns represent the nodes involved in an edge,\n",
    "and the rest of the columns represent the metadata.\n",
    "\n",
    "### Combined Representation\n",
    "\n",
    "In fact, one might also choose to combine\n",
    "the node set and edge set tables together in a merged format:\n",
    "\n",
    "A, circle, 5\n",
    "B, circle, 7\n",
    "C, square, 9\n",
    "\n",
    "```\n",
    "n1, n2, colour, shape1, num1, shape2, num2\n",
    "A,  C,  red,    circle, 5,    square, 9\n",
    "B,  C,  orange, circle, 7,    square, 9\n",
    "A,  B,  yellow, circle, 5,    circle, 7\n",
    "C,  A,  green,  square, 9,    circle, 5\n",
    "```\n",
    "\n",
    "In this chapter, the datasets that we will be looking at\n",
    "are going to be formatted in both ways.\n",
    "Let's get going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will be working with the Divvy bike sharing dataset.\n",
    "\n",
    "To illustrate working with data in the separated node- and edge-set format,\n",
    "we will be loading in the 2013 data.\n",
    "On the other hand, to illustrate how we handle data in combined/merged format,\n",
    "we will be loading in the 2019 Q4 data.\n",
    "\n",
    "> Divvy is a bike sharing service in Chicago.\n",
    "> Since 2013, Divvy has released their bike sharing dataset to the public.\n",
    "> The 2013 dataset is comprised of two files: \n",
    "> - `Divvy_Stations_2013.csv`, containing the stations in the system, and\n",
    "> - `DivvyTrips_2013.csv`, containing the trips.\n",
    "\n",
    "Let's dig in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to unzip the dataset.\n",
    "Here's a Python function that you can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# This block of code checks to make sure that a particular directory is present.\n",
    "if \"divvy_2013\" not in os.listdir(here() / 'datasets/'):\n",
    "    print('Unzipping the divvy_2013.zip file in the datasets folder.')\n",
    "    with zipfile.ZipFile(here() / \"datasets/divvy_2013.zip\",\"r\") as zip_ref:\n",
    "        zip_ref.extractall(here() / 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stations = pd.read_csv(here() / 'datasets/divvy_2013/Divvy_Stations_2013.csv', parse_dates=['online date'], encoding='utf-8')\n",
    "stations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(here() / 'datasets/divvy_2013/Divvy_Trips_2013.csv', \n",
    "                    parse_dates=['starttime', 'stoptime'])\n",
    "trips.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor\n",
    "trips.groupby([\"from_station_id\", \"to_station_id\"]).count().reset_index().select_columns([\"from_station_id\", \"to_station_id\", \"trip_id\"]).rename_column(\"trip_id\", \"num_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nams",
   "language": "python",
   "name": "nams"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
